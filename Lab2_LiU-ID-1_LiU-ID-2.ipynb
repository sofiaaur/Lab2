{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboration 2: SÃ¶kagenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, the environment is fully observable. This means that the agent has complete knowledge of the world, i.e., it knows where all the food is located and where the walls are). This means that the agent can plan its path through the room before performing any actions. To do this, the agent needs keep track of how its actions will affect the world (i.e. maintain an internal state) and have some search strategy for exploring the search space to reach the desired goal state.\n",
    "\n",
    "The lab is divided into two parts. In part 1, you will implement the `State` class used to represent and generate new states based on the actions performed by the agent. In part 2, you will implement a search strategy based on you implementation of `State`.\n",
    "\n",
    "In preparation for this lab, especially part 2, we recommend reading Chapter 3 on search algorithms in *Artificial Intelligence: A Modern Approach*. A basic understanding of the principles underlying the classical search algorithms will be assumed throughout this lab.\n",
    "\n",
    "As a reminder, the actions that can be performed by a Pacman agent are: \n",
    "- *GoForward*: Take one step forward\n",
    "- *GoRight*: Turn 90 degrees right and take one step forward\n",
    "- *GoLeft*: Turn 90 degrees left and take one step forward\n",
    "- *GoBack*: Turn and 180 degrees and take one step forward\n",
    "- *Stop*: Shut down the agent\n",
    "- Any other command: No effect\n",
    "\n",
    "*Note: If the the Pacman window freezes, you can still (usually) re-run the code. If this does not work, try `Kernel/Restart`, or restart the Jupyter Notebook* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Implementing the State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to complete the class below to represent the state of the agent and the room. The state can be used to generate **new possible states** from the agent's current state. For example, assume that the agent is standing at a coordinate with no adjacent walls. From this state, the agent can move forward, backward, left, and right. Performing either of these actions should result in new states (not modifications of the current instance!).\n",
    "\n",
    "The initial state contains the agent's starting position **(1,1)**, the agent's starting direction **(1,0)**, and a dictionary representing the map of the room. Directions are represented as tuples, indicating how the agents coordinates changes if the agent takes one step forward: (1,0) = east, (0,-1) = south, (-1,0) = west, (0,1) = north\n",
    "\n",
    "In the map, coordinates (e.g. (1,1)) are used as keys and the values are either **w** (indicating a wall) or <b>*</b> (indicating food). Coordinates that are not represented in the map are assumed to be empty spaces.\n",
    "\n",
    "For an action and some state, the corresponding **move** method returns a new instance of `State` that represents the state that would result if the action would be executed given the parent state (i.e., we are \"thinking ahead\"). It's important to consider, for instance, how the agent's position changes, if any food is eaten, and the actions that has led to the current state. If an action results in a collision with a wall, no new state should be generated (instead the method should return `None`).\n",
    "\n",
    "This part can be a bit tricky, so it's a good idea to keep pen and paper handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Position API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend that you use the Position API to help you manage position information. The `Position` class will help you find the coordinates that result from moving the agent in a given direction. It will also help you generate new directions when the agent turns. Have a look at the methods available in the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from positionUtil import Position\n",
    "# the current position of the agent is x=2 and y=5\n",
    "pos = (2,5)\n",
    "# the agent is facing east, moving forward would add 1 to x and 0 to y\n",
    "direction = (1,0)\n",
    "# call the static helper method in the Position class\n",
    "new_pos = Position.get_forward(pos, direction)\n",
    "print(f\"Moving east from {pos} results in {new_pos}\\n\")\n",
    "\n",
    "help(Position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from positionUtil import *\n",
    "from pacman import *\n",
    "from agents import BaseAgent\n",
    "from keyboardAgents import KeyboardAgent\n",
    "\n",
    "class ModelBasedAgent(BaseAgent):\n",
    "    \n",
    "    class State(BaseAgent.State):\n",
    "        def __init__(self, position, direction, room_map):\n",
    "            print(f\"position = {position}\")\n",
    "            print(f\"direction = {direction}\")\n",
    "            print(f\"room_map = {room_map}\")\n",
    "\n",
    "        def move_right(self):\n",
    "            \"\"\"Return the new state resulting from moving right\"\"\"\n",
    "            print(\"-> GoRight\")\n",
    "            return None\n",
    "\n",
    "        def move_left(self):\n",
    "            \"\"\"Return the new state resulting from moving left\"\"\"\n",
    "            print(\"-> GoLeft\")\n",
    "            return None\n",
    "\n",
    "        def move_forward(self):\n",
    "            \"\"\"Return the new state resulting from moving forward\"\"\"\n",
    "            print(\"-> GoForward\")\n",
    "            return None\n",
    "\n",
    "        def move_back(self):\n",
    "            \"\"\"Return the new state resulting from moving backwards\"\"\"\n",
    "            print(\"-> GoBack\")\n",
    "            return None\n",
    "\n",
    "        def get_position(self):\n",
    "            \"\"\"Get the position of the agent\"\"\"\n",
    "            return \"?\"\n",
    "\n",
    "        def get_food(self):\n",
    "            \"\"\"Get the position of all food as a list\"\"\"\n",
    "            return \"?\"\n",
    "\n",
    "        def get_direction(self):\n",
    "            \"\"\" Return the direction that the agent is facing\"\"\"\n",
    "            return \"?\"\n",
    "\n",
    "        def get_actions(self):\n",
    "            \"\"\"Return all the actions neccessary to reach this state\"\"\"\n",
    "            return \"?\"\n",
    "\n",
    "\n",
    "    def search(self, start_state):\n",
    "        \"\"\"\n",
    "        Search for a sequence of actions that will allow the pacman to\n",
    "        devour all the food in the room.\n",
    "        \"\"\"\n",
    "        ## Leave this method until you get to part 2\n",
    "        start_time = time.time()\n",
    "        return [\"GoForward\", \"GoForward\", \"GoLeft\", \"GoLeft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control agent using keyboard arrows\n",
    "ModelBasedAgent.mode = \"keyboard\"\n",
    "\n",
    "# Print a representation of the current state when an action is actually executed\n",
    "ModelBasedAgent.printing = True\n",
    "\n",
    "# Run ModelBasedAgent in the room layout \"layouts/custom.lay\"\n",
    "args = readCommand([\"--pacman\", ModelBasedAgent,\n",
    "                    \"--layout\", \"smallEmpty\"])\n",
    "runGames(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**: Implement the methods in the `State` class above. Test your implementation by manually controlling the agent using the arrow keys on your keyboard. Verify that the reported position, direction, actions, and food locations match up with the printout of the agent's state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**: In your own words, describe the terms optimal and complete from an AI perspective. For each of the algorithms below, state whether they are optimal and/or complete. Assume that each algorithm is equipped with simple type of loop detection.\n",
    "\n",
    "**Answer**: ...\n",
    "\n",
    "- breadth-first: ?\n",
    "- depth-first: ?\n",
    "- depth-limited: ?\n",
    "- iterative deepening: ?\n",
    "- greedy: ?\n",
    "- A*: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**: In your own words, describe what is meant by heuristics and what they are used for in AI. What is meant by an admissible heuristic?\n",
    "\n",
    "**Answer**: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the agent in `search` mode. Try modifying the predefined list of actions returned by the `search` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let the agent \"search\" for a solution\n",
    "ModelBasedAgent.mode = \"search\"\n",
    "# Enable/disable printing\n",
    "ModelBasedAgent.printing = False\n",
    "\n",
    "# Run ModelBasedAgent in the room layout \"layouts/smallEmpty.lay\"\n",
    "args = readCommand([\"--pacman\", ModelBasedAgent,\n",
    "                    \"--layout\", \"smallEmpty\"])\n",
    "runGames(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**: Draw a small example of the Pacman-world search tree down to depth 3 (starting from depth 0) with the same starting coordinate and direction as in the lab. Assume that all coordinates containing a 0 (e.g., (0,10) and (5,0)) are walls. Each node following the initial state should represent a new coordinate, and the edges should be labeled based on the action performed. Show only the \"legal\" actions and do not expand nodes that you consider to be duplicates of a previous state. Show this to your lab assistant to make sure that you have understood the principles of how a search tree is generated.\n",
    "\n",
    "*Tip: To include a picture in your Jupyter Notebook, simply save your image to disk and reference it like this: `![alt text](real-python-logo.ab1a167d9717.svg)`* E.g.\n",
    "![alt text](real-python-logo.ab1a167d9717.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4**: Implement a breadth-first search algorithm in the `search` method above and return the list of actions required to eat all the food and then `Stop`. *Add comments to the code where appropriate*. Limit the number of states that can be explored to 10,000. A correct implementation should be able to solve all the easy and moderate layouts in the layout directory.\n",
    "\n",
    "To successfully complete the task, you will need implement some type of loop control that allows you to ignore states that are equivalent to some previously explored state in the search. Without at least some basic loop control, even the easy problems will generate more than 10,000 states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predefined layouts have the following optimal solutions:\n",
    "```\n",
    "tinyEmpty       : optimal solution is 3 steps   (easy)\n",
    "smallEmpty      : optimal solution is 8 steps   (easy)\n",
    "smallLabyrinth  : optimal solution is 26 steps  (moderate)\n",
    "mediumLabyrinth : optimal solution is 47 steps  (moderate)\n",
    "mediumEmpty     : optimal solution is 32 steps  (moderate)\n",
    "bigLabyrinth    : optimal solution is 134 steps (difficult)\n",
    "bigEmpty        : optimal solution is 54 steps  (difficult)\n",
    "\n",
    "Complexity of the rooms:\n",
    "trivial         : can be solved without loop control\n",
    "easy/moderate   : requires loop control\n",
    "difficult       : requires heuristics to guide the search\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6**: Briefly describe how your algorithm works. Imagine that you are explaining it to someone who doesn't have access to your code. Also describe how your loop detection works and how you decide if two states can be regarded equivalent.\n",
    "\n",
    "**Answer**: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5**: Is the new agent more intelligent than the agent that was implemented in the previous lab? Why or why not? Motivate your answer.\n",
    "\n",
    "**Answer**: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6 (for VG):**: Adapt your solution to implement a heuristic A* search. The heuristic must be admissible. Compare the number of expanded nodes to your original breadth-first implementation; this should be a significant improvement. You should be able to solve at least one of the difficult layouts. Briefly describe your heuristic in your own words.\n",
    "\n",
    "**Answer**: ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
